{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `adpapi` v1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from collections.abc import Callable\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from dataclasses import dataclass\n",
    "from enum import StrEnum\n",
    "from typing import Any\n",
    "from urllib.parse import quote\n",
    "\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_path_parameters(path: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract path parameter names from a URL path template.\n",
    "\n",
    "    Args:\n",
    "        path: URL path template (e.g., '/hr/workers/{workerId}')\n",
    "\n",
    "    Returns:\n",
    "        List of parameter names found in curly braces\n",
    "\n",
    "    Example:\n",
    "        >>> extract_path_parameters('/hr/workers/{workerId}/jobs/{jobId}')\n",
    "        ['workerId', 'jobId']\n",
    "    \"\"\"\n",
    "    pattern = r\"\\{([^}]+)\\}\"\n",
    "    return re.findall(pattern, path)\n",
    "\n",
    "\n",
    "def validate_path_parameters(path: str, parameters: dict[str, Any]) -> tuple[bool, list[str]]:\n",
    "    \"\"\"\n",
    "    Validate that all required path parameters are provided.\n",
    "\n",
    "    Args:\n",
    "        path: URL path template\n",
    "        provided_params: Dictionary of provided parameters\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (is_valid, missing_parameters)\n",
    "    \"\"\"\n",
    "    required_params = extract_path_parameters(path)\n",
    "    missing_params = [param for param in required_params if param not in parameters]\n",
    "    return (len(missing_params) == 0, missing_params)\n",
    "\n",
    "\n",
    "def substitute_path_parameters(path: str, params: dict[str, Any]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Substitute path parameters with actual values.\n",
    "    Handles both single values and lists of values.\n",
    "\n",
    "    Args:\n",
    "        path: URL path template\n",
    "        params: Dictionary of parameter values (can be single values or lists)\n",
    "\n",
    "    Returns:\n",
    "        List of fully constructed paths (one per value if lists provided)\n",
    "\n",
    "    Example:\n",
    "        >>> substitute_path_parameters('/hr/workers/{workerId}', {'workerId': ['123', '456']})\n",
    "        ['/hr/workers/123', '/hr/workers/456']\n",
    "    \"\"\"\n",
    "    is_valid, missing = validate_path_parameters(path, params)\n",
    "    if not is_valid:\n",
    "        raise ValueError(f\"Missing required path parameters: {', '.join(missing)}\")\n",
    "\n",
    "    # Determine if any parameter is a list\n",
    "    list_params = {k: v for k, v in params.items() if isinstance(v, list)}\n",
    "\n",
    "    if not list_params:\n",
    "        # No lists, single substitution\n",
    "        return [_substitute_single_path(path, params)]\n",
    "\n",
    "    # Handle list parameters - generate all combinations\n",
    "    # For simplicity, assume only one parameter should be a list\n",
    "    if len(list_params) > 1:\n",
    "        raise ValueError(\"Only one path parameter can accept a list of values\")\n",
    "\n",
    "    list_param_name, list_values = next(iter(list_params.items()))\n",
    "    result_paths = []\n",
    "\n",
    "    for value in list_values:\n",
    "        current_params = params.copy()\n",
    "        current_params[list_param_name] = value\n",
    "        result_paths.append(_substitute_single_path(path, current_params))\n",
    "\n",
    "    return result_paths\n",
    "\n",
    "\n",
    "def resolve_path_parameter_sets(path: str, params: dict[str, Any]) -> list[dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Resolve the set of path parameters for each URL that would be generated.\n",
    "\n",
    "    Returns one dict per URL, containing the scalar parameter values used\n",
    "    for that specific request. Mirrors the expansion logic in\n",
    "    ``substitute_path_parameters``.\n",
    "\n",
    "    Args:\n",
    "        path: URL path template (e.g., '/hr/workers/{workerId}')\n",
    "        params: Dictionary of parameter values (can be single values or lists)\n",
    "\n",
    "    Returns:\n",
    "        List of dicts, one per generated URL, with string values\n",
    "\n",
    "    Example:\n",
    "        >>> resolve_path_parameter_sets('/hr/workers/{workerId}', {'workerId': ['A', 'B']})\n",
    "        [{'workerId': 'A'}, {'workerId': 'B'}]\n",
    "    \"\"\"\n",
    "    path_param_names = set(extract_path_parameters(path))\n",
    "    # Build base scalar params (only those that appear in the path template)\n",
    "    base_params = {\n",
    "        k: str(v) for k, v in params.items() if k in path_param_names and not isinstance(v, list)\n",
    "    }\n",
    "\n",
    "    list_params = {k: v for k, v in params.items() if k in path_param_names and isinstance(v, list)}\n",
    "\n",
    "    if not list_params:\n",
    "        return [base_params] if base_params else [{}]\n",
    "\n",
    "    list_param_name, list_values = next(iter(list_params.items()))\n",
    "    result = []\n",
    "    for value in list_values:\n",
    "        param_set = base_params.copy()\n",
    "        param_set[list_param_name] = str(value)\n",
    "        result.append(param_set)\n",
    "    return result\n",
    "\n",
    "\n",
    "def _substitute_single_path(path: str, params: dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Substitute a single set of parameters into a path template.\n",
    "\n",
    "    Args:\n",
    "        path: URL path template\n",
    "        params: Dictionary of single parameter values (no lists)\n",
    "\n",
    "    Returns:\n",
    "        Fully constructed path with URL-encoded values\n",
    "    \"\"\"\n",
    "    result = path\n",
    "    for param_name, param_value in params.items():\n",
    "        placeholder = f\"{{{param_name}}}\"\n",
    "        # URL encode the parameter value\n",
    "        encoded_value = quote(str(param_value), safe=\"\")\n",
    "        result = result.replace(placeholder, encoded_value)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def is_valid_endpoint_path(path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Validate that an endpoint path follows expected format.\n",
    "\n",
    "    Checks that the path starts with a slash, has balanced curly braces, and that\n",
    "    placeholders are properly formatted.\n",
    "\n",
    "    Args:\n",
    "        path: URL path to validate\n",
    "\n",
    "    Returns:\n",
    "        True if path is valid, False otherwise\n",
    "\n",
    "    Example:\n",
    "        >>> is_valid_endpoint_path('/hr/workers/{workerId}')\n",
    "        True\n",
    "        >>> is_valid_endpoint_path('invalid')\n",
    "        False\n",
    "    \"\"\"\n",
    "    # Path should start with /\n",
    "    if not path.startswith(\"/\"):\n",
    "        return False\n",
    "\n",
    "    # Check for balanced curly braces\n",
    "    if path.count(\"{\") != path.count(\"}\"):\n",
    "        return False\n",
    "\n",
    "    # Check that placeholders are properly formatted\n",
    "    pattern = r\"\\{[a-zA-Z_][a-zA-Z0-9_]*\\}\"\n",
    "    placeholders = re.findall(r\"\\{[^}]*\\}\", path)\n",
    "\n",
    "    return all(re.match(pattern, placeholder) for placeholder in placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logging():\n",
    "    logging.basicConfig(\n",
    "        filename=\"app.log\",\n",
    "        filemode=\"w\",\n",
    "        level=logging.DEBUG,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    )\n",
    "    # Add console handler\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.DEBUG)\n",
    "    console_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n",
    "    logging.getLogger().addHandler(console_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## odata_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expr:\n",
    "    \"\"\"Abstract base class for OData filter expression AST nodes.\n",
    "\n",
    "    All filter expressions inherit from this class and implement the to_odata()\n",
    "    method to convert the expression tree to an OData filter string.\n",
    "\n",
    "    Supports logical operator overloading:\n",
    "    - & (and): Combines two expressions with AND\n",
    "    - | (or): Combines two expressions with OR\n",
    "    - ~ (not): Inverts an expression with NOT\n",
    "    \"\"\"\n",
    "\n",
    "    def to_odata(self) -> str:\n",
    "        \"\"\"Convert this expression to an OData filter string.\n",
    "\n",
    "        Returns:\n",
    "            str: The OData v4 filter string representation of this expression.\n",
    "\n",
    "        Raises:\n",
    "            NotImplementedError: This method must be implemented by subclasses.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __and__(self, other: \"Expr\") -> \"Expr\":\n",
    "        \"\"\"Combine two expressions with logical AND.\n",
    "\n",
    "        Args:\n",
    "            other: Another Expr to combine with AND.\n",
    "\n",
    "        Returns:\n",
    "            Expr: A new binary operation node representing the AND operation.\n",
    "\n",
    "        Example:\n",
    "            >>> expr1 = FilterExpression.field('age').gt(18)\n",
    "            >>> expr2 = FilterExpression.field('status').eq('Active')\n",
    "            >>> combined = expr1 & expr2\n",
    "        \"\"\"\n",
    "        return BinaryOp(self, \"and\", other)\n",
    "\n",
    "    def __or__(self, other: \"Expr\") -> \"Expr\":\n",
    "        \"\"\"Combine two expressions with logical OR.\n",
    "\n",
    "        Args:\n",
    "            other: Another Expr to combine with OR.\n",
    "\n",
    "        Returns:\n",
    "            Expr: A new binary operation node representing the OR operation.\n",
    "\n",
    "        Example:\n",
    "            >>> expr1 = FilterExpression.field('status').eq('Active')\n",
    "            >>> expr2 = FilterExpression.field('status').eq('Pending')\n",
    "            >>> combined = expr1 | expr2\n",
    "        \"\"\"\n",
    "        return BinaryOp(self, \"or\", other)\n",
    "\n",
    "    def __invert__(self) -> \"Expr\":\n",
    "        \"\"\"Invert an expression with logical NOT.\n",
    "\n",
    "        Returns:\n",
    "            Expr: A new unary operation node applying NOT to this expression.\n",
    "\n",
    "        Example:\n",
    "            >>> expr = FilterExpression.field('isTerminated').eq(True)\n",
    "            >>> inverted = ~expr  # NOT isTerminated = true\n",
    "        \"\"\"\n",
    "        return UnaryOp(\"not\", self)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Field(Expr):\n",
    "    \"\"\"Represents a field reference in an OData filter expression.\n",
    "\n",
    "    Fields are identified by their path (e.g., 'worker.person.firstName').\n",
    "    This class provides a fluent API for building filter conditions on fields.\n",
    "\n",
    "    Attributes:\n",
    "        path (str): The dot-separated path to the field, supporting nested properties.\n",
    "\n",
    "    Example:\n",
    "        >>> field = Field('worker.hireDate')\n",
    "        >>> field.eq('2020-01-01').to_odata()\n",
    "        \"(worker/hireDate eq '2020-01-01')\"\n",
    "    \"\"\"\n",
    "\n",
    "    path: str\n",
    "\n",
    "    # comparisons\n",
    "    def eq(self, val: Any) -> \"BinaryOp\":\n",
    "        \"\"\"Create an equality comparison filter (field = value).\n",
    "\n",
    "        Args:\n",
    "            val: The value to compare against. Can be string, number, boolean, or None.\n",
    "\n",
    "        Returns:\n",
    "            BinaryOp: A binary operation representing the equality condition.\n",
    "\n",
    "        Example:\n",
    "            >>> FilterExpression.field('status').eq('Active').to_odata()\n",
    "            \"(status eq 'Active')\"\n",
    "        \"\"\"\n",
    "        return BinaryOp(self, \"eq\", literal(val))\n",
    "\n",
    "    def ne(self, val: Any) -> \"BinaryOp\":\n",
    "        \"\"\"Create a not-equal comparison filter (field != value).\n",
    "\n",
    "        Args:\n",
    "            val: The value to compare against. Can be string, number, boolean, or None.\n",
    "\n",
    "        Returns:\n",
    "            BinaryOp: A binary operation representing the not-equal condition.\n",
    "\n",
    "        Example:\n",
    "            >>> FilterExpression.field('status').ne('Inactive').to_odata()\n",
    "            \"(status ne 'Inactive')\"\n",
    "        \"\"\"\n",
    "        return BinaryOp(self, \"ne\", literal(val))\n",
    "\n",
    "    def gt(self, val: Any) -> \"BinaryOp\":\n",
    "        \"\"\"Create a greater-than comparison filter (field > value).\n",
    "\n",
    "        Args:\n",
    "            val: The value to compare against. Typically a number or date string.\n",
    "\n",
    "        Returns:\n",
    "            BinaryOp: A binary operation representing the greater-than condition.\n",
    "\n",
    "        Example:\n",
    "            >>> FilterExpression.field('salary').gt(50000).to_odata()\n",
    "            \"(salary gt 50000)\"\n",
    "        \"\"\"\n",
    "        return BinaryOp(self, \"gt\", literal(val))\n",
    "\n",
    "    def ge(self, val: Any) -> \"BinaryOp\":\n",
    "        \"\"\"Create a greater-than-or-equal comparison filter (field >= value).\n",
    "\n",
    "        Args:\n",
    "            val: The value to compare against. Typically a number or date string.\n",
    "\n",
    "        Returns:\n",
    "            BinaryOp: A binary operation representing the greater-than-or-equal condition.\n",
    "\n",
    "        Example:\n",
    "            >>> FilterExpression.field('hireDate').ge('2020-01-01').to_odata()\n",
    "            \"(hireDate ge '2020-01-01')\"\n",
    "        \"\"\"\n",
    "        return BinaryOp(self, \"ge\", literal(val))\n",
    "\n",
    "    def lt(self, val: Any) -> \"BinaryOp\":\n",
    "        \"\"\"Create a less-than comparison filter (field < value).\n",
    "\n",
    "        Args:\n",
    "            val: The value to compare against. Typically a number or date string.\n",
    "\n",
    "        Returns:\n",
    "            BinaryOp: A binary operation representing the less-than condition.\n",
    "\n",
    "        Example:\n",
    "            >>> FilterExpression.field('salary').lt(100000).to_odata()\n",
    "            \"(salary lt 100000)\"\n",
    "        \"\"\"\n",
    "        return BinaryOp(self, \"lt\", literal(val))\n",
    "\n",
    "    def le(self, val: Any) -> \"BinaryOp\":\n",
    "        \"\"\"Create a less-than-or-equal comparison filter (field <= value).\n",
    "\n",
    "        Args:\n",
    "            val: The value to compare against. Typically a number or date string.\n",
    "\n",
    "        Returns:\n",
    "            BinaryOp: A binary operation representing the less-than-or-equal condition.\n",
    "\n",
    "        Example:\n",
    "            >>> FilterExpression.field('retirementDate').le('2025-12-31').to_odata()\n",
    "            \"(retirementDate le '2025-12-31')\"\n",
    "        \"\"\"\n",
    "        return BinaryOp(self, \"le\", literal(val))\n",
    "\n",
    "    # string functions\n",
    "    def contains(self, val: Any) -> \"Func\":\n",
    "        \"\"\"Create a substring contains filter for string fields.\n",
    "\n",
    "        Args:\n",
    "            val: The substring to search for within the field value.\n",
    "\n",
    "        Returns:\n",
    "            Func: A function call representing the contains operation.\n",
    "\n",
    "        Example:\n",
    "            >>> FilterExpression.field('lastName').contains('Smith').to_odata()\n",
    "            \"contains(lastName, 'Smith')\"\n",
    "        \"\"\"\n",
    "        return Func(\"contains\", [self, literal(val)])\n",
    "\n",
    "    def startswith(self, val: Any) -> \"Func\":\n",
    "        \"\"\"Create a string starts-with filter.\n",
    "\n",
    "        Args:\n",
    "            val: The prefix to search for at the start of the field value.\n",
    "\n",
    "        Returns:\n",
    "            Func: A function call representing the startswith operation.\n",
    "\n",
    "        Example:\n",
    "            >>> FilterExpression.field('firstName').startswith('John').to_odata()\n",
    "            \"startswith(firstName, 'John')\"\n",
    "        \"\"\"\n",
    "        return Func(\"startswith\", [self, literal(val)])\n",
    "\n",
    "    def endswith(self, val: Any) -> \"Func\":\n",
    "        \"\"\"Create a string ends-with filter.\n",
    "\n",
    "        Args:\n",
    "            val: The suffix to search for at the end of the field value.\n",
    "\n",
    "        Returns:\n",
    "            Func: A function call representing the endswith operation.\n",
    "\n",
    "        Example:\n",
    "            >>> FilterExpression.field('email').endswith('@company.com').to_odata()\n",
    "            \"endswith(email, '@company.com')\"\n",
    "        \"\"\"\n",
    "        return Func(\"endswith\", [self, literal(val)])\n",
    "\n",
    "    # emulate IN as disjunction\n",
    "    def isin(self, values: list[Any]) -> \"Expr\":\n",
    "        \"\"\"Create an IN filter for multiple values (field IN (val1, val2, ...)).\n",
    "\n",
    "        Since OData v4 doesn't have a native IN operator, this is implemented as\n",
    "        a series of OR conditions joined together.\n",
    "\n",
    "        Args:\n",
    "            values: A list of values to check against. If empty, returns false.\n",
    "\n",
    "        Returns:\n",
    "            Expr: An expression representing the IN operation. For empty lists,\n",
    "                  returns an always-false condition (1 eq 0).\n",
    "\n",
    "        Example:\n",
    "            >>> statuses = ['Active', 'OnLeave', 'Pending']\n",
    "            >>> FilterExpression.field('status').isin(statuses).to_odata()\n",
    "            \"((status eq 'Active') or ((status eq 'OnLeave') or (status eq 'Pending')))\"\n",
    "        \"\"\"\n",
    "        if not values:\n",
    "            # empty IN -> false; represent as (1 eq 0)\n",
    "            return BinaryOp(Literal(1), \"eq\", Literal(0))\n",
    "        expr: Expr = BinaryOp(self, \"eq\", literal(values[0]))\n",
    "        for v in values[1:]:\n",
    "            clause = BinaryOp(self, \"eq\", literal(v))\n",
    "            expr = BinaryOp(expr, \"or\", clause)\n",
    "        return expr\n",
    "\n",
    "    def to_odata(self) -> str:\n",
    "        \"\"\"Convert this field reference to an OData path string.\n",
    "\n",
    "        Converts dot notation to forward slash notation for OData v4 compliance.\n",
    "\n",
    "        Returns:\n",
    "            str: The OData-compliant field path.\n",
    "\n",
    "        Example:\n",
    "            >>> Field('worker.person.firstName').to_odata()\n",
    "            'worker/person/firstName'\n",
    "        \"\"\"\n",
    "        # Convert dot notation to forward slash for OData v4 compliance\n",
    "        # Input: \"workers.workAssignments.reportsTo.positionID\"\n",
    "        # Output: \"workers/workAssignments/reportsTo/positionID\"\n",
    "        return self.path.replace(\".\", \"/\")\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Literal(Expr):\n",
    "    \"\"\"Represents a literal value in an OData filter expression.\n",
    "\n",
    "    Handles conversion of Python values (strings, numbers, booleans, None) to\n",
    "    their OData string representation.\n",
    "\n",
    "    Attributes:\n",
    "        value: The Python value to represent as a literal.\n",
    "\n",
    "    Example:\n",
    "        >>> lit = Literal(42)\n",
    "        >>> lit.to_odata()\n",
    "        '42'\n",
    "        >>> lit = Literal('hello')\n",
    "        >>> lit.to_odata()\n",
    "        \\\"'hello'\\\"\n",
    "    \"\"\"\n",
    "\n",
    "    value: Any\n",
    "\n",
    "    def to_odata(self) -> str:\n",
    "        \"\"\"Convert this literal value to an OData string representation.\n",
    "\n",
    "        Handles proper escaping of quotes and conversion of Python types to\n",
    "        OData literal syntax.\n",
    "\n",
    "        Returns:\n",
    "            str: The OData-compliant literal representation.\n",
    "            - null for None values\n",
    "            - true/false for booleans\n",
    "            - numeric representation for numbers\n",
    "            - quoted and escaped string for text values\n",
    "\n",
    "        Example:\n",
    "            >>> Literal(None).to_odata()\n",
    "            'null'\n",
    "            >>> Literal(True).to_odata()\n",
    "            'true'\n",
    "            >>> Literal(\"O'Reilly\").to_odata()\n",
    "            \\\"'O''Reilly'\\\"\n",
    "        \"\"\"\n",
    "        v = self.value\n",
    "        if v is None:\n",
    "            return \"null\"\n",
    "        if isinstance(v, bool):\n",
    "            return \"true\" if v else \"false\"\n",
    "        if isinstance(v, (int, float)):\n",
    "            return str(v)\n",
    "        # Default: string; escape single quotes by doubling them\n",
    "        s = str(v).replace(\"'\", \"''\")\n",
    "        return f\"'{s}'\"\n",
    "\n",
    "\n",
    "def literal(v: Any) -> Literal:\n",
    "    \"\"\"Create a Literal value from a Python value.\n",
    "\n",
    "    Convenience function for creating Literal nodes.\n",
    "\n",
    "    Args:\n",
    "        v: Any Python value (string, number, boolean, None).\n",
    "\n",
    "    Returns:\n",
    "        Literal: A new Literal node representing the value.\n",
    "\n",
    "    Example:\n",
    "        >>> literal(42).to_odata()\n",
    "        '42'\n",
    "        >>> literal('test').to_odata()\n",
    "        \\\"'test'\\\"\n",
    "    \"\"\"\n",
    "    return Literal(v)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Func(Expr):\n",
    "    \"\"\"Represents a function call in an OData filter expression.\n",
    "\n",
    "    Functions can include built-in OData string functions like contains,\n",
    "    startswith, and endswith, or potentially custom functions.\n",
    "\n",
    "    Attributes:\n",
    "        name (str): The function name (e.g., 'contains', 'startswith', 'endswith').\n",
    "        args (List[Expr]): List of argument expressions to pass to the function.\n",
    "\n",
    "    Example:\n",
    "        >>> func = Func('contains', [Field('lastName'), Literal('Smith')])\n",
    "        >>> func.to_odata()\n",
    "        \\\"contains(lastName, 'Smith')\\\"\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    args: list[Expr]\n",
    "\n",
    "    def to_odata(self) -> str:\n",
    "        \"\"\"Convert this function call to an OData string representation.\n",
    "\n",
    "        Returns:\n",
    "            str: The OData-compliant function call syntax.\n",
    "\n",
    "        Example:\n",
    "            >>> Func('startswith', [Field('email'), Literal('admin')]).to_odata()\n",
    "            \\\"startswith(email, 'admin')\\\"\n",
    "        \"\"\"\n",
    "        args_s = \", \".join(a.to_odata() for a in self.args)\n",
    "        return f\"{self.name}({args_s})\"\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class BinaryOp(Expr):\n",
    "    \"\"\"Represents a binary operation in an OData filter expression.\n",
    "\n",
    "    Binary operations include comparisons (eq, ne, gt, ge, lt, le) and logical\n",
    "    operators (and, or).\n",
    "\n",
    "    Attributes:\n",
    "        left (Expr): The left operand expression.\n",
    "        op (str): The operator ('eq', 'ne', 'gt', 'ge', 'lt', 'le', 'and', 'or').\n",
    "        right (Expr): The right operand expression.\n",
    "\n",
    "    Example:\n",
    "        >>> op = BinaryOp(Field('age'), 'gt', Literal(18))\n",
    "        >>> op.to_odata()\n",
    "        '(age gt 18)'\n",
    "    \"\"\"\n",
    "\n",
    "    left: Expr\n",
    "    # * Could be replaced with enum\n",
    "    op: str  #'eq','ne','gt','ge','lt','le','and','or'\n",
    "    right: Expr\n",
    "\n",
    "    def to_odata(self) -> str:\n",
    "        \"\"\"Convert this binary operation to an OData string representation.\n",
    "\n",
    "        Wraps the entire operation in parentheses to ensure correct precedence\n",
    "        in complex expressions.\n",
    "\n",
    "        Returns:\n",
    "            str: The OData-compliant operation syntax with parentheses.\n",
    "\n",
    "        Example:\n",
    "            >>> BinaryOp(Field('a'), 'eq', Literal(1)).to_odata()\n",
    "            '(a eq 1)'\n",
    "        \"\"\"\n",
    "        # Parentheses ensure correct precedence in mixed expressions\n",
    "        return f\"({self.left.to_odata()} {self.op} {self.right.to_odata()})\"\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class UnaryOp(Expr):\n",
    "    \"\"\"Represents a unary operation in an OData filter expression.\n",
    "\n",
    "    Currently supports the NOT operator for inverting boolean expressions.\n",
    "\n",
    "    Attributes:\n",
    "        op (str): The operator (typically 'not').\n",
    "        expr (Expr): The operand expression to apply the operator to.\n",
    "\n",
    "    Example:\n",
    "        >>> op = UnaryOp('not', BinaryOp(Field('isActive'), 'eq', Literal(True)))\n",
    "        >>> op.to_odata()\n",
    "        '(not (isActive eq true))'\n",
    "    \"\"\"\n",
    "\n",
    "    op: str  # 'not'\n",
    "    expr: Expr\n",
    "\n",
    "    def to_odata(self) -> str:\n",
    "        \"\"\"Convert this unary operation to an OData string representation.\n",
    "\n",
    "        Returns:\n",
    "            str: The OData-compliant operation syntax with parentheses.\n",
    "\n",
    "        Example:\n",
    "            >>> UnaryOp('not', Field('isActive')).to_odata()\n",
    "            '(not isActive)'\n",
    "        \"\"\"\n",
    "        return f\"({self.op} {self.expr.to_odata()})\"\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Public facade\n",
    "# ---------------------------\n",
    "\n",
    "\n",
    "class FilterExpression(Expr):\n",
    "    \"\"\"Public API for creating and managing OData filter expressions.\n",
    "\n",
    "    Attributes:\n",
    "        _node (Expr): The internal AST node representing the expression.\n",
    "\n",
    "    Examples:\n",
    "        Build filters programmatically:\n",
    "        >>> f = FilterExpression.field('firstName').eq('John')\n",
    "        >>> f.to_odata()\n",
    "        \"(firstName eq 'John')\"\n",
    "\n",
    "        Combine with logical operators:\n",
    "        >>> f1 = FilterExpression.field('age').gt(18)\n",
    "        >>> f2 = FilterExpression.field('status').eq('Active')\n",
    "        >>> combined = f1 & f2\n",
    "        >>> combined.to_odata()\n",
    "        \"((age gt 18) and (status eq 'Active'))\"\n",
    "\n",
    "        Parse existing OData filter strings:\n",
    "        >>> f = FilterExpression.from_string(\"firstName eq 'John'\")\n",
    "        >>> f.to_odata()\n",
    "        \"(firstName eq 'John')\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, node: Expr):\n",
    "        \"\"\"Initialize a FilterExpression with an AST node.\n",
    "\n",
    "        Args:\n",
    "            node: An Expr AST node representing the filter expression.\n",
    "        \"\"\"\n",
    "        self._node = node\n",
    "\n",
    "    # faÃ§ade pass-through\n",
    "    def to_odata(self) -> str:\n",
    "        \"\"\"Convert this filter expression to an OData v4 filter string.\n",
    "\n",
    "        Returns:\n",
    "            str: The complete OData filter string ready for use in API requests.\n",
    "\n",
    "        Example:\n",
    "            >>> FilterExpression.field('status').eq('Active').to_odata()\n",
    "            \"(status eq 'Active')\"\n",
    "        \"\"\"\n",
    "        return self._node.to_odata()\n",
    "\n",
    "    # convenience constructors\n",
    "    @staticmethod\n",
    "    def field(path: str) -> Field:\n",
    "        \"\"\"Create a field reference for building filter conditions.\n",
    "\n",
    "        This is the primary entry point for building filters. The returned Field\n",
    "        object provides a fluent API with comparison and string function methods.\n",
    "\n",
    "        Args:\n",
    "            path (str): Dot-separated field path (e.g., 'worker.person.firstName').\n",
    "                       Supports nested properties accessible through the API.\n",
    "\n",
    "        Returns:\n",
    "            Field: A Field object with methods for building conditions.\n",
    "\n",
    "        Example:\n",
    "            >>> f = FilterExpression.field('lastName')\n",
    "            >>> f = f.eq('Smith')\n",
    "            >>> f.to_odata()\n",
    "            \"(lastName eq 'Smith')\"\n",
    "\n",
    "        Commonly used field paths:\n",
    "            - 'worker.firstName' - Worker's first name\n",
    "            - 'worker.lastName' - Worker's last name\n",
    "            - 'hireDate' - Date of hire\n",
    "            - 'department' - Department assignment\n",
    "            - 'salary' - Salary information\n",
    "        \"\"\"\n",
    "        return Field(path)\n",
    "\n",
    "    # parse a limited OData subset into an AST\n",
    "    @staticmethod\n",
    "    def from_string(s: str) -> \"FilterExpression\":\n",
    "        \"\"\"Parse an OData filter string into a FilterExpression.\n",
    "\n",
    "        This parser supports a subset of OData v4 filter syntax, including:\n",
    "        - Comparison operators: eq, ne, gt, ge, lt, le\n",
    "        - Logical operators: and, or, not\n",
    "        - Boolean operators with parentheses for grouping\n",
    "        - String functions: contains(), startswith(), endswith()\n",
    "        - Literal values: strings, numbers, booleans, null\n",
    "        - Field paths with dot notation\n",
    "\n",
    "        Args:\n",
    "            s (str): An OData filter string to parse.\n",
    "\n",
    "        Returns:\n",
    "            FilterExpression: A parsed and structured filter expression.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the filter string has syntax errors or uses unsupported\n",
    "                       OData features.\n",
    "\n",
    "        Example:\n",
    "            >>> f = FilterExpression.from_string(\n",
    "            ...     \"(firstName eq 'John') and (lastName eq 'Doe')\"\n",
    "            ... )\n",
    "            >>> f.to_odata()\n",
    "            \"((firstName eq 'John') and (lastName eq 'Doe'))\"\n",
    "\n",
    "            Parse a string function:\n",
    "            >>> f = FilterExpression.from_string(\n",
    "            ...     \"contains(email, '@company.com')\"\n",
    "            ... )\n",
    "            >>> f.to_odata()\n",
    "            \"contains(email, '@company.com')\"\n",
    "        \"\"\"\n",
    "        node = _FilterParser(s).parse()\n",
    "        return FilterExpression(node)\n",
    "\n",
    "    # combinators keep returning FilterExpression\n",
    "    def __and__(self, other: Expr) -> \"FilterExpression\":\n",
    "        \"\"\"Combine this expression with another using logical AND.\n",
    "\n",
    "        Args:\n",
    "            other: Another FilterExpression or Expr to combine with AND.\n",
    "\n",
    "        Returns:\n",
    "            FilterExpression: A new combined filter expression.\n",
    "\n",
    "        Example:\n",
    "            >>> expr1 = FilterExpression.field('age').gt(18)\n",
    "            >>> expr2 = FilterExpression.field('status').eq('Active')\n",
    "            >>> combined = expr1 & expr2\n",
    "            >>> combined.to_odata()\n",
    "            \"((age gt 18) and (status eq 'Active'))\"\n",
    "        \"\"\"\n",
    "        return FilterExpression(BinaryOp(self._node, \"and\", _unwrap(other)))\n",
    "\n",
    "    def __or__(self, other: Expr) -> \"FilterExpression\":\n",
    "        \"\"\"Combine this expression with another using logical OR.\n",
    "\n",
    "        Args:\n",
    "            other: Another FilterExpression or Expr to combine with OR.\n",
    "\n",
    "        Returns:\n",
    "            FilterExpression: A new combined filter expression.\n",
    "\n",
    "        Example:\n",
    "            >>> expr1 = FilterExpression.field('status').eq('Active')\n",
    "            >>> expr2 = FilterExpression.field('status').eq('Pending')\n",
    "            >>> combined = expr1 | expr2\n",
    "            >>> combined.to_odata()\n",
    "            \"((status eq 'Active') or (status eq 'Pending'))\"\n",
    "        \"\"\"\n",
    "        return FilterExpression(BinaryOp(self._node, \"or\", _unwrap(other)))\n",
    "\n",
    "    def __invert__(self) -> \"FilterExpression\":\n",
    "        \"\"\"Invert this expression using logical NOT.\n",
    "\n",
    "        Returns:\n",
    "            FilterExpression: A new inverted filter expression.\n",
    "\n",
    "        Example:\n",
    "            >>> expr = FilterExpression.field('isTerminated').eq(True)\n",
    "            >>> inverted = ~expr\n",
    "            >>> inverted.to_odata()\n",
    "            \"(not (isTerminated eq true))\"\n",
    "        \"\"\"\n",
    "        return FilterExpression(UnaryOp(\"not\", self._node))\n",
    "\n",
    "\n",
    "def _unwrap(e: Expr | FilterExpression) -> Expr:\n",
    "    \"\"\"Extract the internal AST node from a FilterExpression if needed.\n",
    "\n",
    "    Helper function to unwrap FilterExpression instances for combining with\n",
    "    other expressions. Returns the input unchanged if it's already an Expr.\n",
    "\n",
    "    Args:\n",
    "        e: An Expr or FilterExpression.\n",
    "\n",
    "    Returns:\n",
    "        Expr: The underlying AST node.\n",
    "    \"\"\"\n",
    "    return e._node if isinstance(e, FilterExpression) else e\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Minimal OData filter parser\n",
    "# Supports:\n",
    "#   - parentheses\n",
    "#   - and/or/not\n",
    "#   - eq, ne, gt, ge, lt, le\n",
    "#   - contains(), startswith(), endswith()\n",
    "#   - identifiers with dot (field paths), string/number/bool/null\n",
    "# ---------------------------\n",
    "\n",
    "\"\"\"Token specification for OData filter lexer.\n",
    "\n",
    "Defines regex patterns for recognizing different token types in OData filter\n",
    "strings, including operators, literals, identifiers, and special syntax.\n",
    "\"\"\"\n",
    "_TOKEN_SPEC = [\n",
    "    (\"WS\", r\"[ \\t\\n\\r]+\"),\n",
    "    (\"LPAREN\", r\"\\(\"),\n",
    "    (\"RPAREN\", r\"\\)\"),\n",
    "    (\"COMMA\", r\",\"),\n",
    "    (\"OP\", r\"\\b(eq|ne|gt|ge|lt|le|and|or|not)\\b\"),\n",
    "    (\"FUNC\", r\"\\b(contains|startswith|endswith)\\b\"),\n",
    "    (\"BOOL\", r\"\\b(true|false)\\b\"),\n",
    "    (\"NULL\", r\"\\bnull\\b\"),\n",
    "    (\"NUMBER\", r\"-?\\d+(\\.\\d+)?\"),\n",
    "    (\"IDENT\", r\"[A-Za-z_][A-Za-z0-9_\\.]*\"),\n",
    "    (\"STRING\", r\"'([^']|'')*'\"),\n",
    "]\n",
    "\n",
    "\"\"\"Compiled regex for tokenizing OData filter strings.\"\"\"\n",
    "_TOKEN_RE = re.compile(\"|\".join(f\"(?P<{name}>{pat})\" for name, pat in _TOKEN_SPEC), re.IGNORECASE)\n",
    "\n",
    "\n",
    "class _Token:\n",
    "    \"\"\"Internal representation of a lexical token.\n",
    "\n",
    "    Attributes:\n",
    "        type (str): The token type (e.g., 'IDENT', 'OP', 'STRING').\n",
    "        value (str): The raw text value of the token.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, typ: str, val: str):\n",
    "        \"\"\"Initialize a token.\n",
    "\n",
    "        Args:\n",
    "            typ: The token type identifier.\n",
    "            val: The token's string value.\n",
    "        \"\"\"\n",
    "        self.type = typ\n",
    "        self.value = val\n",
    "\n",
    "\n",
    "class _FilterParser:\n",
    "    \"\"\"Internal parser for OData filter strings.\n",
    "\n",
    "    Implements a recursive descent parser for a subset of OData v4 filters.\n",
    "    Produces an AST of Expr nodes that can be converted to OData syntax.\n",
    "\n",
    "    Supported grammar:\n",
    "        expr       := or_expr\n",
    "        or_expr    := and_expr ('or' and_expr)*\n",
    "        and_expr   := not_expr ('and' not_expr)*\n",
    "        not_expr   := [not'] cmp_expr\n",
    "        cmp_expr   := primary (OP primary)?\n",
    "        primary    := FUNC '(' arg_list ')' | '(' expr ')' | literal | field\n",
    "        arg_list   := expr (',' expr)*\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text: str):\n",
    "        \"\"\"Initialize the parser with a filter string.\n",
    "\n",
    "        Args:\n",
    "            text: The OData filter string to parse.\n",
    "        \"\"\"\n",
    "        self.tokens = list(self._tokenize(text))\n",
    "        self.pos = 0\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        \"\"\"Tokenize an OData filter string.\n",
    "\n",
    "        Args:\n",
    "            text: The filter string to tokenize.\n",
    "\n",
    "        Yields:\n",
    "            _Token: Individual tokens from the input.\n",
    "        \"\"\"\n",
    "        for m in _TOKEN_RE.finditer(text):\n",
    "            typ = m.lastgroup\n",
    "            val = m.group(typ)\n",
    "            if typ == \"WS\":\n",
    "                continue\n",
    "            yield _Token(typ, val)\n",
    "        # implicit EOF\n",
    "\n",
    "    def _peek(self) -> _Token | None:\n",
    "        \"\"\"Look at the current token without consuming it.\n",
    "\n",
    "        Returns:\n",
    "            _Token: The current token, or None if at EOF.\n",
    "        \"\"\"\n",
    "        return self.tokens[self.pos] if self.pos < len(self.tokens) else None\n",
    "\n",
    "    def _eat(self, typ: str) -> _Token:\n",
    "        \"\"\"Consume and return the next token if it matches expected type.\n",
    "\n",
    "        Args:\n",
    "            typ: The expected token type.\n",
    "\n",
    "        Returns:\n",
    "            _Token: The consumed token.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the current token doesn't match the expected type.\n",
    "        \"\"\"\n",
    "        tok = self._peek()\n",
    "        if not tok or tok.type != typ:\n",
    "            raise ValueError(f\"Expected {typ}, found {tok.type if tok else 'EOF'}\")\n",
    "        self.pos += 1\n",
    "        return tok\n",
    "\n",
    "    def _match(self, typ: str) -> _Token | None:\n",
    "        \"\"\"Optionally consume the next token if it matches a type.\n",
    "\n",
    "        Args:\n",
    "            typ: The expected token type.\n",
    "\n",
    "        Returns:\n",
    "            _Token: The consumed token if matched, None otherwise.\n",
    "        \"\"\"\n",
    "        tok = self._peek()\n",
    "        if tok and tok.type == typ:\n",
    "            self.pos += 1\n",
    "            return tok\n",
    "        return None\n",
    "\n",
    "    # Grammar (Pratt-ish recursive descent):\n",
    "    # expr  := or_expr\n",
    "    # or_expr := and_expr ('or' and_expr)*\n",
    "    # and_expr := not_expr ('and' not_expr)*\n",
    "    # not_expr := ['not'] cmp_expr\n",
    "    # cmp_expr := primary (OP primary)?\n",
    "    # primary := FUNC '(' arg_list ')' | '(' expr ')' | literal | field\n",
    "    # arg_list := expr (',' expr)*\n",
    "\n",
    "    def parse(self) -> Expr:\n",
    "        \"\"\"Parse the entire filter string into an AST.\n",
    "\n",
    "        Returns:\n",
    "            Expr: The root node of the parsed expression tree.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the filter string has syntax errors or unexpected tokens.\n",
    "        \"\"\"\n",
    "        expr = self._parse_or()\n",
    "        tok = self._peek()\n",
    "        if tok:\n",
    "            raise ValueError(f\"Unexpected token: {tok.value}\")\n",
    "        return expr\n",
    "\n",
    "    def _parse_or(self) -> Expr:\n",
    "        \"\"\"Parse OR expressions (lowest precedence).\n",
    "\n",
    "        Returns:\n",
    "            Expr: The parsed OR expression.\n",
    "        \"\"\"\n",
    "        node = self._parse_and()\n",
    "        while (tok := self._peek()) is not None and tok.type == \"OP\" and tok.value.lower() == \"or\":\n",
    "            self._eat(\"OP\")\n",
    "            rhs = self._parse_and()\n",
    "            node = BinaryOp(node, \"or\", rhs)\n",
    "        return node\n",
    "\n",
    "    def _parse_and(self) -> Expr:\n",
    "        \"\"\"Parse AND expressions.\n",
    "\n",
    "        Returns:\n",
    "            Expr: The parsed AND expression.\n",
    "        \"\"\"\n",
    "        node = self._parse_not()\n",
    "        while (tok := self._peek()) is not None and tok.type == \"OP\" and tok.value.lower() == \"and\":\n",
    "            self._eat(\"OP\")\n",
    "            rhs = self._parse_not()\n",
    "            node = BinaryOp(node, \"and\", rhs)\n",
    "        return node\n",
    "\n",
    "    def _parse_not(self) -> Expr:\n",
    "        \"\"\"Parse NOT expressions.\n",
    "\n",
    "        Returns:\n",
    "            Expr: The parsed NOT expression.\n",
    "        \"\"\"\n",
    "        if (tok := self._peek()) is not None and tok.type == \"OP\" and tok.value.lower() == \"not\":\n",
    "            self._eat(\"OP\")\n",
    "            return UnaryOp(\"not\", self._parse_cmp())\n",
    "        return self._parse_cmp()\n",
    "\n",
    "    def _parse_cmp(self) -> Expr:\n",
    "        \"\"\"Parse comparison expressions (eq, ne, gt, ge, lt, le).\n",
    "\n",
    "        Returns:\n",
    "            Expr: The parsed comparison or primary expression.\n",
    "        \"\"\"\n",
    "        left = self._parse_primary()\n",
    "        tok = self._peek()\n",
    "        if tok and tok.type == \"OP\" and tok.value.lower() in {\"eq\", \"ne\", \"gt\", \"ge\", \"lt\", \"le\"}:\n",
    "            op = tok.value.lower()\n",
    "            self._eat(\"OP\")\n",
    "            right = self._parse_primary()\n",
    "            return BinaryOp(left, op, right)\n",
    "        return left\n",
    "\n",
    "    def _parse_primary(self) -> Expr:\n",
    "        \"\"\"Parse primary expressions (function calls, parentheses, literals, fields).\n",
    "\n",
    "        Returns:\n",
    "            Expr: The parsed primary expression.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an unexpected token is encountered or EOF is reached.\n",
    "        \"\"\"\n",
    "        tok = self._peek()\n",
    "        if not tok:\n",
    "            raise ValueError(\"Unexpected EOF\")\n",
    "\n",
    "        if tok.type == \"FUNC\":\n",
    "            name = tok.value.lower()\n",
    "            self._eat(\"FUNC\")\n",
    "            self._eat(\"LPAREN\")\n",
    "            args = [self._parse()]\n",
    "            while self._match(\"COMMA\"):\n",
    "                args.append(self._parse())\n",
    "            self._eat(\"RPAREN\")\n",
    "            return Func(name, args)\n",
    "\n",
    "        if tok.type == \"LPAREN\":\n",
    "            self._eat(\"LPAREN\")\n",
    "            node = self._parse_or()\n",
    "            self._eat(\"RPAREN\")\n",
    "            return node\n",
    "\n",
    "        if tok.type == \"IDENT\":\n",
    "            self._eat(\"IDENT\")\n",
    "            return Field(tok.value)\n",
    "\n",
    "        if tok.type == \"STRING\":\n",
    "            self._eat(\"STRING\")\n",
    "            # unescape doubled single quotes\n",
    "            inner = tok.value[1:-1].replace(\"''\", \"'\")\n",
    "            return Literal(inner)\n",
    "\n",
    "        if tok.type == \"NUMBER\":\n",
    "            self._eat(\"NUMBER\")\n",
    "            return Literal(float(tok.value) if \".\" in tok.value else int(tok.value))\n",
    "\n",
    "        if tok.type == \"BOOL\":\n",
    "            self._eat(\"BOOL\")\n",
    "            return Literal(tok.value.lower() == \"true\")\n",
    "\n",
    "        if tok.type == \"NULL\":\n",
    "            self._eat(\"NULL\")\n",
    "            return Literal(None)\n",
    "\n",
    "        raise ValueError(f\"Unexpected token: {tok.value}\")\n",
    "\n",
    "    def _parse(self) -> Expr:\n",
    "        \"\"\"Parse an expression (internal method for recursive parsing).\n",
    "\n",
    "        Used internally for parsing function arguments and ensures proper\n",
    "        precedence handling in recursive contexts.\n",
    "\n",
    "        Returns:\n",
    "            Expr: The parsed expression.\n",
    "        \"\"\"\n",
    "        return self._parse_or()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"Example usage of the FilterExpression API.\n",
    "\n",
    "    This section demonstrates both approaches:\n",
    "    1. Programmatic filter building using the fluent API\n",
    "    2. Parsing existing OData filter strings\n",
    "\n",
    "    Run this file directly to see example output:\n",
    "        python -m src.adpapi.odata_filters\n",
    "\n",
    "    Examples cover:\n",
    "    - Simple equality filters\n",
    "    - Comparison operators (eq, ne, gt, ge, lt, le)\n",
    "    - String functions (contains, startswith, endswith)\n",
    "    - Complex expressions with logical operators (and, or, not)\n",
    "    - Multiple value matching with isin()\n",
    "    - Parsing OData filter strings\n",
    "    \"\"\"\n",
    "    # Example: Building filters programmatically with the fluent API\n",
    "    print(\"=== Programmatic Filter Building ===\\n\")\n",
    "\n",
    "    # Simple equality filter\n",
    "    filter1 = FilterExpression.field(\"worker.person.legalName.givenName\").eq(\"John\")\n",
    "    print(f\"givenName = 'John':\\n  {filter1.to_odata()}\\n\")\n",
    "\n",
    "    # Comparison operators\n",
    "    filter2 = FilterExpression.field(\"employee.hireDate\").ge(\"2020-01-01\")\n",
    "    print(f\"hireDate >= '2020-01-01':\\n  {filter2.to_odata()}\\n\")\n",
    "\n",
    "    # String functions\n",
    "    filter3 = FilterExpression.field(\"worker.person.legalName.familyName\").contains(\"Smith\")\n",
    "    print(f\"familyName contains 'Smith':\\n  {filter3.to_odata()}\\n\")\n",
    "\n",
    "    # Complex expressions with and/or operators (wrap in FilterExpression)\n",
    "    filter4 = FilterExpression(\n",
    "        FilterExpression.field(\"worker.person.legalName.givenName\").eq(\"John\")\n",
    "    ) & FilterExpression(FilterExpression.field(\"worker.person.legalName.familyName\").eq(\"Doe\"))\n",
    "    print(f\"givenName = 'John' AND familyName = 'Doe':\\n  {filter4.to_odata()}\\n\")\n",
    "\n",
    "    # Complex expression with or\n",
    "    filter5 = FilterExpression(\n",
    "        FilterExpression.field(\"department\").eq(\"Engineering\")\n",
    "    ) | FilterExpression(FilterExpression.field(\"department\").eq(\"Sales\"))\n",
    "    print(f\"department = 'Engineering' OR department = 'Sales':\\n  {filter5.to_odata()}\\n\")\n",
    "\n",
    "    # Using isin for multiple values\n",
    "    filter6 = FilterExpression.field(\"status\").isin([\"Active\", \"OnLeave\", \"Pending\"])\n",
    "    print(f\"status IN ('Active', 'OnLeave', 'Pending'):\\n  {filter6.to_odata()}\\n\")\n",
    "\n",
    "    # Using not operator (wrap in FilterExpression)\n",
    "    filter7 = ~FilterExpression(FilterExpression.field(\"isTerminated\").eq(True))\n",
    "    print(f\"NOT isTerminated = true:\\n  {filter7.to_odata()}\\n\")\n",
    "\n",
    "    print(\"=== Parsing OData Filter Strings ===\\n\")\n",
    "\n",
    "    # Parse existing OData filter strings\n",
    "    odata_str = \"(worker.person.legalName.givenName eq 'John') and (hireDate ge '2020-01-01')\"\n",
    "    try:\n",
    "        filter8 = FilterExpression.from_string(odata_str)\n",
    "        print(f\"Parsed filter:\\n  Input:  {odata_str}\")\n",
    "        print(f\"  Output: {filter8.to_odata()}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Parse error: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class RequestMethod(StrEnum):\n",
    "    GET = \"GET\"\n",
    "    POST = \"POST\"\n",
    "    PUT = \"PUT\"\n",
    "    DELETE = \"DELETE\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ApiSession:\n",
    "    session: requests.Session\n",
    "    cert: tuple[str, str]\n",
    "    get_headers: Callable[[], dict] | None = None\n",
    "    headers: dict | None = None\n",
    "    params: dict | None = None\n",
    "    timeout: int = 30\n",
    "    data: Any | None = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.get_headers is None:\n",
    "            # Default to empty header generation\n",
    "            self.get_headers = lambda: {}\n",
    "        if self.params is None:\n",
    "            self.params = {}\n",
    "\n",
    "    def set_params(self, params: dict):\n",
    "        self.params = params\n",
    "\n",
    "    def set_data(self, data: Any):\n",
    "        self.data = data\n",
    "\n",
    "    def _get_request_function(self, method: RequestMethod) -> Callable:\n",
    "        match method:\n",
    "            case RequestMethod.GET:\n",
    "                return self.session.get\n",
    "            case RequestMethod.POST:\n",
    "                return self.session.post\n",
    "            case RequestMethod.PUT:\n",
    "                return self.session.put\n",
    "            case RequestMethod.DELETE:\n",
    "                return self.session.delete\n",
    "\n",
    "        raise ValueError(f\"Unsupported method {method}\")\n",
    "\n",
    "    def _request(self, url: str, method: RequestMethod = RequestMethod.GET) -> requests.Response:\n",
    "        \"\"\"Execute HTTP request with specified method, headers, params, and optional data.\n",
    "\n",
    "        Args:\n",
    "            url: The request URL\n",
    "            method: HTTP method (GET, POST, PUT, DELETE)\n",
    "\n",
    "        Returns:\n",
    "            requests.Response object\n",
    "\n",
    "        Raises:\n",
    "            requests.RequestException: If request fails\n",
    "        \"\"\"\n",
    "        request_fn = self._get_request_function(method)\n",
    "        # Generate headers on call time for up-to-date token\n",
    "        assert self.get_headers is not None\n",
    "        headers = self.get_headers()\n",
    "        kwargs = {\n",
    "            \"headers\": headers,\n",
    "            \"params\": self.params,\n",
    "            \"cert\": self.cert,\n",
    "            \"timeout\": self.timeout,\n",
    "        }\n",
    "        if self.data is not None:\n",
    "            kwargs[\"json\"] = self.data\n",
    "        response = request_fn(url, **kwargs)\n",
    "\n",
    "        try:\n",
    "            response.raise_for_status()\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            headers = dict(response.headers)\n",
    "            data = response.json()\n",
    "            logger.error(\n",
    "                f\"Request failed for {method} request to url: {url} with params {self.params}\\n\"\n",
    "                f\"Response Headers: {json.dumps(headers, indent=2)}\\n\"\n",
    "                f\"Response Body: {json.dumps(data, indent=2)}\\n\"\n",
    "                f\"Error:\\n{e}\"\n",
    "            )\n",
    "            raise\n",
    "\n",
    "        return response\n",
    "\n",
    "    def get(self, url: str) -> requests.Response:\n",
    "        return self._request(url, RequestMethod.GET)\n",
    "\n",
    "    def post(self, url: str, data: Any | None = None) -> requests.Response:\n",
    "        if data is not None:\n",
    "            self.set_data(data)\n",
    "        return self._request(url, RequestMethod.POST)\n",
    "\n",
    "    def put(self, url: str, data: Any | None = None) -> requests.Response:\n",
    "        if data is not None:\n",
    "            self.set_data(data)\n",
    "        return self._request(url, RequestMethod.PUT)\n",
    "\n",
    "    def delete(self, url: str) -> requests.Response:\n",
    "        return self._request(url, RequestMethod.DELETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "DEFAULT_TIMEOUT = 30\n",
    "TOKEN_BUFFER_SECONDS = 300  # Refresh token 5 minutes before expiration\n",
    "\n",
    "\n",
    "CERT_DEFAULT = \"certificate.pem\"\n",
    "KEY_DEFAULT = \"adp.key\"\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class AdpCredentials:\n",
    "    client_id: str\n",
    "    client_secret: str\n",
    "    cert_path: str | None = CERT_DEFAULT\n",
    "    key_path: str | None = KEY_DEFAULT\n",
    "\n",
    "    @staticmethod\n",
    "    def from_env() -> \"AdpCredentials\":\n",
    "        client_id = os.getenv(\"CLIENT_ID\")\n",
    "        client_secret = os.getenv(\"CLIENT_SECRET\")\n",
    "\n",
    "        # Read optional mTLS certificate/key paths (defaults assume files in project root).\n",
    "        cert_path = os.getenv(\"CERT_PATH\")\n",
    "        key_path = os.getenv(\"KEY_PATH\")\n",
    "\n",
    "        if cert_path is None:\n",
    "            logger.warning(\n",
    "                f\"No environment variables found for CERT_PATH, defaulting to {CERT_DEFAULT}\"\n",
    "            )\n",
    "\n",
    "        if key_path is None:\n",
    "            logger.warning(\n",
    "                f\"No environment variables found for KEY_PATH, defaulting to {KEY_DEFAULT}\"\n",
    "            )\n",
    "\n",
    "        if client_id is None or client_secret is None:\n",
    "            raise ValueError(\"CLIENT_ID and CLIENT_SECRET environment variables must be set\")\n",
    "\n",
    "        return AdpCredentials(client_id, client_secret, cert_path, key_path)\n",
    "\n",
    "\n",
    "class AdpApiClient:\n",
    "    def __init__(self, credentials: AdpCredentials):\n",
    "        if credentials.cert_path is None or credentials.key_path is None:\n",
    "            raise ValueError(\"Certificate path and key path must not be None\")\n",
    "        if not os.path.exists(credentials.cert_path) or not os.path.exists(credentials.key_path):\n",
    "            logger.error(\"Missing Certificate or Key File.\")\n",
    "            raise FileNotFoundError(\"Certificate or key file not found.\")\n",
    "\n",
    "        self.client_id = credentials.client_id\n",
    "        self.client_secret = credentials.client_secret\n",
    "        self.cert_path = credentials.cert_path\n",
    "        self.key_path = credentials.key_path\n",
    "        self.cert = (self.cert_path, self.key_path)\n",
    "        self.session = requests.Session()\n",
    "        self._setup_retry_strategy()\n",
    "\n",
    "        # Token expiration tracking\n",
    "        self.token: str | None = None\n",
    "        self.token_expires_at = 0\n",
    "\n",
    "    @property\n",
    "    def payload(self) -> dict[str, str]:\n",
    "        return {\n",
    "            \"grant_type\": \"client_credentials\",\n",
    "            \"client_id\": self.client_id,\n",
    "            \"client_secret\": self.client_secret,\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def base_url(self) -> str:\n",
    "        return \"https://api.adp.com\"\n",
    "\n",
    "    def _setup_retry_strategy(self, retries: int = 3, backoff_factor: float = 0.5):\n",
    "        \"\"\"Configure retry strategy with exponential backoff for HTTP requests.\"\"\"\n",
    "        retry_strategy = Retry(\n",
    "            total=retries,\n",
    "            backoff_factor=backoff_factor,\n",
    "            status_forcelist=[429, 500, 502, 503, 504],\n",
    "            allowed_methods=[\"GET\", \"POST\"],\n",
    "        )\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        self.session.mount(\"http://\", adapter)\n",
    "        self.session.mount(\"https://\", adapter)\n",
    "        logger.debug(f\"Retry strategy configured: {retries} retries with {backoff_factor}s backoff\")\n",
    "\n",
    "    def _is_token_expired(self) -> bool:\n",
    "        \"\"\"Check if token is expired or will expire soon.\"\"\"\n",
    "        return time.time() >= self.token_expires_at - TOKEN_BUFFER_SECONDS\n",
    "\n",
    "    def _get_token(self, timeout: int = DEFAULT_TIMEOUT) -> str:\n",
    "        logger.debug(\"Requesting Token from ADP Accounts endpoint\")\n",
    "        TOKEN_URL = \"https://accounts.adp.com/auth/oauth/v2/token\"\n",
    "        try:\n",
    "            response = self.session.post(\n",
    "                TOKEN_URL,\n",
    "                data=self.payload,\n",
    "                cert=self.cert,\n",
    "                timeout=timeout,\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            token_json = response.json()\n",
    "            token = token_json.get(\"access_token\")\n",
    "            if not token:\n",
    "                raise ValueError(\"No access token in response\")\n",
    "\n",
    "            # Track token expiration\n",
    "            expires_in = token_json.get(\"expires_in\", 3600)  # Default 1 hour\n",
    "            self.token_expires_at = time.time() + expires_in\n",
    "            logger.info(f\"Token Acquired (expires in {expires_in}s)\")\n",
    "            return token\n",
    "        except requests.RequestException as e:\n",
    "            logger.error(f\"Token request failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _ensure_valid_token(self, timeout: int = DEFAULT_TIMEOUT):\n",
    "        \"\"\"Refresh token if expired.\"\"\"\n",
    "        if self.token is None or self._is_token_expired():\n",
    "            logger.debug(\"Token expired, refreshing...\")\n",
    "            self.token = self._get_token(timeout)\n",
    "\n",
    "    def _get_headers(self, masked: bool = True) -> dict[str, str]:\n",
    "        \"\"\"Build request headers with Bearer token and masking preference.\"\"\"\n",
    "        # * May need to be tweaked in the future if OData calls or other forms are needed. Not necessary for MVP\n",
    "        accept = \"application/json\"\n",
    "        if not masked:\n",
    "            accept += \";masked=false\"\n",
    "            logging.debug(f\"Calling _get_headers with accept = {accept}\")\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.token}\",\n",
    "            \"Accept\": accept,\n",
    "        }\n",
    "\n",
    "        return headers\n",
    "\n",
    "    def get_masked_headers(self) -> dict[str, str]:\n",
    "        return self._get_headers(True)\n",
    "\n",
    "    def get_unmasked_headers(self) -> dict[str, str]:\n",
    "        return self._get_headers(False)\n",
    "\n",
    "    def _handle_filters(self, filters: str | FilterExpression | None = None) -> str:\n",
    "        \"\"\"Convert filter input (string or FilterExpression) to OData string.\n",
    "\n",
    "        Args:\n",
    "            filters: Filter as string or FilterExpression object, or None\n",
    "\n",
    "        Returns:\n",
    "            OData filter string, or empty string if no filters\n",
    "        \"\"\"\n",
    "        if filters is None:\n",
    "            return \"\"\n",
    "        elif isinstance(filters, str):\n",
    "            try:\n",
    "                filters = FilterExpression.from_string(filters)\n",
    "            except ValueError:\n",
    "                logger.error(f\"Error parsing filter expression: {filters}\")\n",
    "                raise\n",
    "\n",
    "        # Remove outer parentheses added by BinaryOp if present\n",
    "        odata_str = filters.to_odata()\n",
    "        if odata_str.startswith(\"(\") and odata_str.endswith(\")\"):\n",
    "            odata_str = odata_str[1:-1]\n",
    "        return odata_str\n",
    "\n",
    "    def _clean_endpoint(self, endpoint: str) -> str:\n",
    "        starts_with_base = endpoint.startswith(self.base_url)\n",
    "        starts_with_path = endpoint.startswith(\"/\")\n",
    "\n",
    "        if not (starts_with_base or starts_with_path):\n",
    "            logger.error(f\"Incorrect Endpoint Received {endpoint}\")\n",
    "            raise ValueError(f\"Incorrect Endpoint Received: {endpoint}\")\n",
    "\n",
    "        if starts_with_base:\n",
    "            endpoint = endpoint.split(self.base_url)[1]\n",
    "            logger.warning(\n",
    "                \"Full URL Specification not needed, prefer to use the endpoint string.\\n\"\n",
    "                f\"(Ex: Prefer {endpoint} over {self.base_url}{endpoint}).\"\n",
    "            )\n",
    "\n",
    "        return endpoint\n",
    "\n",
    "    def call_endpoint(\n",
    "        self,\n",
    "        endpoint: str,\n",
    "        select: list[str] | None = None,\n",
    "        filters: str | FilterExpression | None = None,\n",
    "        masked: bool = True,\n",
    "        timeout: int = DEFAULT_TIMEOUT,\n",
    "        page_size: int = 100,\n",
    "        max_requests: int | None = None,\n",
    "    ) -> list[dict]:\n",
    "        \"\"\"Call any Registered ADP Endpoint\n",
    "\n",
    "        Args:\n",
    "            endpoint (str): API Endpoint or qualified URL to call\n",
    "            select (List[str]): Table Columns to pull\n",
    "            masked (bool, optional): Mask Sensitive Columns Containing Personally Identifiable Information. Defaults to True.\n",
    "            filters (str | FilterExpression, optional): OData Filter Expression. Strings will be passed directly,\n",
    "                or OData strings can be automatically created from `adpapi.odata_filters.FilterExpression` objects\n",
    "            timeout (int, optional): Time to wait on. Defaults to 30.\n",
    "            page_size (int, optional): Amount of records to pull per API call (max 100). Defaults to 100.\n",
    "            max_requests (Optional[int], optional): Maximum number of requests to make (for quick testing). Defaults to None.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: When given an endpoint not following the call convention\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: The collection of API responses\n",
    "        \"\"\"\n",
    "\n",
    "        # Request Cleanup and Validation Logic\n",
    "        if page_size > 100:\n",
    "            logger.warning(\"Page size > 100 not supported by API endpoint. Limiting to 100.\")\n",
    "            page_size = 100\n",
    "\n",
    "        # Output/Request Initialization\n",
    "        endpoint = self._clean_endpoint(endpoint)\n",
    "        url = self.base_url + endpoint\n",
    "        filter_param = self._handle_filters(filters)\n",
    "        # Populate here instead of mutable default arguments\n",
    "        if select is None:\n",
    "            select = []\n",
    "        select_param = \",\".join(select)\n",
    "        output = []\n",
    "        skip = 0\n",
    "\n",
    "        get_headers_fn = self.get_masked_headers if masked else self.get_unmasked_headers\n",
    "\n",
    "        call_session = ApiSession(self.session, self.cert, get_headers_fn, timeout=timeout)\n",
    "\n",
    "        params: dict[str, Any] = {\"$top\": page_size}\n",
    "        if select_param:\n",
    "            logging.debug(f\"Restricting OData Selection to {select_param}\")\n",
    "            params[\"$select\"] = select_param\n",
    "        if filter_param:\n",
    "            logging.debug(f\"Filtering Results according to OData query: {filter_param}\")\n",
    "            params[\"$filter\"] = filter_param\n",
    "\n",
    "        while True:\n",
    "            params[\"$skip\"] = skip\n",
    "            call_session.set_params(params)\n",
    "            self._ensure_valid_token(timeout)\n",
    "            response = call_session.get(url)\n",
    "\n",
    "            if response.status_code == 204:\n",
    "                logger.debug(\"End of pagination reached (204 No Content)\")\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                data = response.json()\n",
    "                output.append(data)\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                logger.error(f\"Failed to parse JSON response: {e}\")\n",
    "                raise\n",
    "\n",
    "            if max_requests is not None and len(output) >= max_requests:\n",
    "                logger.debug(f\"Max Requests reached: {max_requests}\")\n",
    "                break\n",
    "            skip += page_size\n",
    "\n",
    "        return output\n",
    "\n",
    "    def call_rest_endpoint(\n",
    "        self,\n",
    "        endpoint: str,\n",
    "        method: str = \"GET\",\n",
    "        masked: bool = True,\n",
    "        timeout: int = DEFAULT_TIMEOUT,\n",
    "        params: dict | None = None,\n",
    "        max_workers: int = 1,\n",
    "        inject_path_params: bool = False,\n",
    "        **kwargs: Any,\n",
    "    ) -> list[dict]:\n",
    "        \"\"\"Call a RestAPI Endpoint\n",
    "\n",
    "        Args:\n",
    "            endpoint (str): the endpoint path template (e.g. '/hr/workers/{workerId}')\n",
    "            method (Optional[str], optional): the HTTP method to use for the request. Defaults to 'GET'.\n",
    "            masked (Optional[bool], optional): whether to use masked headers. Defaults to True.\n",
    "            timeout (Optional[int], optional): the request timeout in seconds. Defaults to DEFAULT_TIMEOUT.\n",
    "            params (Optional[dict], optional): query parameters for the request. Defaults to None.\n",
    "            max_workers (int, optional): maximum number of threads for parallel requests. Defaults to 1 (sequential).\n",
    "            inject_path_params (bool, optional): when True, merge the resolved path parameters\n",
    "                into each response dict. Useful when the API does not echo back identifiers\n",
    "                (e.g. AOIDs) in the response body. Defaults to False.\n",
    "            **kwargs: path parameters to substitute into the endpoint template (e.g workerId=['123', '456']) - can be single values or lists of values for batch requests\n",
    "        Raises:\n",
    "            ValueError: if required path parameters are missing or if endpoint format is incorrect\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: the collection of API responses for each substituted endpoint\n",
    "        \"\"\"\n",
    "        is_valid, missing_params = validate_path_parameters(endpoint, kwargs)\n",
    "        if not is_valid:\n",
    "            raise ValueError(f\"Missing required path parameters: {', '.join(missing_params)}\")\n",
    "\n",
    "        urls = substitute_path_parameters(endpoint, kwargs)\n",
    "        if not urls:\n",
    "            return []\n",
    "\n",
    "        # Establish the call session\n",
    "        get_headers_fn = self.get_masked_headers if masked else self.get_unmasked_headers\n",
    "\n",
    "        call_session = ApiSession(self.session, self.cert, get_headers_fn, timeout=timeout)\n",
    "        if params:\n",
    "            call_session.set_params(params)\n",
    "\n",
    "        # Ensure a valid token once before all requests to avoid race conditions\n",
    "        # with concurrent threads each trying to refresh the token simultaneously.\n",
    "        self._ensure_valid_token(timeout)\n",
    "\n",
    "        def _fetch(url: str) -> dict:\n",
    "            full_url = self.base_url + url\n",
    "            response = call_session._request(url=full_url, method=RequestMethod(method))\n",
    "            try:\n",
    "                data = response.json()\n",
    "                return data\n",
    "            except json.JSONDecodeError as e:\n",
    "                logger.error(f\"Failed to parse JSON response: {e}\")\n",
    "                raise\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            output = list(executor.map(_fetch, urls))\n",
    "\n",
    "        if inject_path_params:\n",
    "            param_sets = resolve_path_parameter_sets(endpoint, kwargs)\n",
    "            for response, param_set in zip(output, param_sets, strict=False):\n",
    "                response.update(param_set)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Context manager entry.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Context manager exit - cleanup session.\"\"\"\n",
    "        self.session.close()\n",
    "        logger.debug(\"Session closed\")\n",
    "        return False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}